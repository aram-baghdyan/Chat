# MagicOnion Production-Ready Chat System

A scalable, production-ready real-time chat system built with .NET 10 and MagicOnion (gRPC).

## Features

- **Real-time bidirectional communication** using MagicOnion StreamingHub
- **Horizontal scalability** with Redis pub/sub backplane
- **Production-ready** with structured logging, health checks, and graceful shutdown
- **Server-initiated notifications** demonstrating push capability
- **Multi-instance support** - messages distributed across all server instances
- **Docker-ready** with Docker Compose orchestration

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Client    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   Server    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ    Redis    ‚îÇ
‚îÇ  (Console)  ‚îÇ gRPC ‚îÇ Instance 1  ‚îÇ Pub  ‚îÇ  (Backplane)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò Sub  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚ñ≤               ‚ñ≤
                             ‚îÇ               ‚îÇ
                             ‚îÇ Pub/Sub       ‚îÇ
                             ‚îÇ               ‚îÇ
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
                     ‚îÇ   Server    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ Instance 2  ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Tech Stack

- **.NET 10** - Latest .NET platform
- **MagicOnion 7.x** - gRPC-based real-time communication
- **Redis** - Message distribution backplane
- **Serilog** - Structured logging
- **MessagePack** - Efficient serialization
- **OpenTelemetry** - Metrics and distributed tracing
- **NGINX** - gRPC reverse proxy with rate limiting
- **Docker & Docker Compose** - Containerization

## Quick Start

### Prerequisites

- .NET 10 SDK
- Docker & Docker Compose (for containerized setup)
- Redis (if running locally without Docker)

### Running with Docker Compose (Recommended)

```bash
# Build and start all services (Redis + 2 server instances)
docker compose up --build

# In separate terminals, connect clients to different instances
docker compose run --rm chat.client
```

### Running Locally

**Terminal 1 - Start Redis:**
```bash
docker run -p 6379:6379 redis:7-alpine
```

**Terminal 2 - Start Server:**
```bash
cd src/Chat.Server
dotnet run
```

**Terminal 3 - Start Client:**
```bash
cd src/Chat.Client
dotnet run
```

## Configuration

Server configuration in `src/Chat.Server/appsettings.json`:

```json
{
  "Redis": {
    "ConnectionString": "localhost:6379"
  },
  "Chat": {
    "ServerNotificationIntervalSeconds": 30,
    "EnableServerNotifications": true
  }
}
```

## Health Checks

- **Liveness:** `http://localhost:5000/health/live`
- **Readiness:** `http://localhost:5000/health/ready` (checks Redis connectivity, reuses the singleton `IConnectionMultiplexer`)

## Observability

OpenTelemetry is configured with ASP.NET Core, runtime, and gRPC-client instrumentation. The application exposes the following custom metrics from the `Chat.Server` meter:

| Metric | Type | Attributes | Description |
|---|---|---|---|
| `chat.connections.active` | UpDownCounter | ‚Äî | Currently connected users |
| `chat.joins.total` | Counter | `outcome`: `success` / `rejected` | Join attempts |
| `chat.messages.sent` | Counter | `type`: `user` / `system` | Messages broadcast |
| `chat.messages.bytes` | Histogram | `type`: `user` / `system` | Broadcast payload sizes (bytes) |
| `chat.group.broadcast.duration` | Histogram | `type`: `user` / `system` | Redis group broadcast latency (ms) |
| `chat.notification.errors` | Counter | ‚Äî | `ServerNotificationService` loop failures |

No exporter is wired by default. Add one (OTLP, Prometheus, Console) through the `.WithMetrics()` / `.WithTracing()` builders in `Program.cs`.

## Project Structure

```
Chat/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ Chat.Contracts/          # Shared interfaces and models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IChatHub.cs         # Hub interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IChatHubReceiver.cs # Client receiver interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MessageData.cs      # Message model
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Constants.cs        # Shared constants
‚îÇ   ‚îú‚îÄ‚îÄ Chat.Server/            # Server application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Hubs/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ChatHub.cs      # Hub implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ServerNotificationService.cs  # Periodic notifications
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Configuration/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ChatOptions.cs  # App configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NoOpReceiver.cs     # Dummy receiver for server-side hub client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Program.cs          # App entry point
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ appsettings.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ Chat.Client/            # Console client
‚îÇ       ‚îú‚îÄ‚îÄ Program.cs
‚îÇ       ‚îú‚îÄ‚îÄ ChatReceiver.cs     # Message receiver implementation
‚îÇ       ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ next-steps.md          # Roadmap and code review findings
‚îÇ   ‚îî‚îÄ‚îÄ plans/                 # Implementation plans
‚îú‚îÄ‚îÄ compose.yaml               # Docker Compose orchestration
‚îî‚îÄ‚îÄ Chat.slnx                  # Solution file
```

## How Multi-Server Works

MagicOnion 7.x uses the **Multicaster** library for Redis-based group distribution:

```csharp
// Program.cs - Enable Redis backplane
builder.Services.AddMagicOnion()
    .UseRedisGroup(
        config => config.ConnectionString = redisConnectionString,
        registerAsDefault: true);  // Critical: must be true for cross-server
```

When `registerAsDefault: true`:
1. All `group.All.OnReceiveMessage()` calls are published to Redis
2. All server instances subscribe to the same Redis channel
3. Each server broadcasts to its local clients

## Testing Multi-Instance Setup

1. Start with Docker Compose: `docker compose up --build`
2. Connect client to instance 1: `docker compose run --rm chat.client` (enter `http://chat.server:8080`)
3. Connect another client to instance 2: `docker compose run --rm chat.client` (enter `http://chat.server.2:8080`)
4. Send messages from either client - both receive messages via Redis backplane

## Production Considerations

‚úÖ **Implemented:**
- Structured logging with Serilog
- Health checks (liveness and readiness, Redis reuses singleton connection)
- Message serialization with MessagePack
- Multi-instance support via MagicOnion Redis backplane
- Docker health checks
- OpenTelemetry metrics and tracing (application metrics, ASP.NET Core, runtime, gRPC client)
- NGINX rate limiting (100 req/s per IP, burst 50)
- Kestrel connection limits (1 000 concurrent connections, 100 HTTP/2 streams per connection)
- Graceful shutdown in `ServerNotificationService`
- `DateTimeOffset` timestamps for round-trip-safe MessagePack serialization

‚ö†Ô∏è **Pending:**
- Reconnection logic for background services
- Fire-and-forget hub methods (`void` returns)

See [docs/next-steps.md](docs/next-steps.md) for detailed findings.

üîú **Consider for production:**
- Authentication & authorization
- Message persistence (database)
- Message history
- User presence tracking
- TLS/SSL certificates
- OTel exporter (OTLP, Prometheus, etc.) ‚Äî instrumentation is wired, exporter is not

## License

MIT
