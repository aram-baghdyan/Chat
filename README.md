# MagicOnion Production-Ready Chat System

A scalable, production-ready real-time chat system built with .NET 10 and MagicOnion (gRPC).

## Features

- **Real-time bidirectional communication** using MagicOnion StreamingHub
- **Horizontal scalability** with Redis pub/sub backplane
- **Production-ready** with structured logging, health checks, and graceful shutdown
- **Server-initiated notifications** demonstrating push capability
- **Multi-instance support** - messages distributed across all server instances
- **Chat history** â€” last N messages replayed on connect, backed by Redis
- **Docker-ready** with Docker Compose orchestration

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚â—„â”€â”€â”€â”€â–ºâ”‚   Server    â”‚â—„â”€â”€â”€â”€â–ºâ”‚    Redis    â”‚
â”‚  (Console)  â”‚ gRPC â”‚ Instance 1  â”‚ Pub  â”‚  (Backplane)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Sub  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–²               â–²
                             â”‚               â”‚
                             â”‚ Pub/Sub       â”‚
                             â”‚               â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
                     â”‚   Server    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Instance 2  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack

- **.NET 10** - Latest .NET platform
- **MagicOnion 7.x** - gRPC-based real-time communication
- **Redis** - Message distribution backplane
- **Serilog** - Structured logging
- **MessagePack** - Efficient serialization
- **OpenTelemetry** - Metrics and distributed tracing
- **NGINX** - gRPC reverse proxy with rate limiting
- **Docker & Docker Compose** - Containerization

## Quick Start

### Prerequisites

- .NET 10 SDK
- Docker & Docker Compose (for containerized setup)
- Redis (if running locally without Docker)

### Running with Docker Compose (Recommended)

```bash
# Build and start all services (Redis + 2 server instances)
docker compose up --build

# In separate terminals, connect clients to different instances
docker compose run --rm chat.client
```

### Running Locally

**Terminal 1 - Start Redis:**
```bash
docker run -p 6379:6379 redis:7-alpine
```

**Terminal 2 - Start Server:**
```bash
cd src/Chat.Server
dotnet run
```

**Terminal 3 - Start Client:**
```bash
cd src/Chat.Client
dotnet run
```

## Configuration

Server configuration in `src/Chat.Server/appsettings.json`:

```json
{
  "Redis": {
    "ConnectionString": "localhost:6379"
  },
  "Chat": {
    "ServerNotificationIntervalSeconds": 30,
    "EnableServerNotifications": true,
    "ServerAddress": "http://localhost:8080",
    "MaxUsernameLength": 50,
    "MaxMessageLength": 4000,
    "MaxHistoryMessages": 100
  }
}
```

## Health Checks

- **Liveness:** `http://localhost:5000/health/live`
- **Readiness:** `http://localhost:5000/health/ready` (checks Redis connectivity, reuses the singleton `IConnectionMultiplexer`)

## Observability

OpenTelemetry is configured with ASP.NET Core, runtime, and gRPC-client instrumentation. The application exposes the following custom metrics from the `Chat.Server` meter:

| Metric | Type | Attributes | Description |
|---|---|---|---|
| `chat.connections.active` | UpDownCounter | â€” | Currently connected users |
| `chat.joins.total` | Counter | `outcome`: `success` / `rejected` | Join attempts |
| `chat.messages.sent` | Counter | `type`: `user` / `system` | Messages broadcast |
| `chat.messages.bytes` | Histogram | `type`: `user` / `system` | Broadcast payload sizes (bytes) |
| `chat.group.broadcast.duration` | Histogram | `type`: `user` / `system` | Redis group broadcast latency (ms) |
| `chat.notification.errors` | Counter | â€” | `ServerNotificationService` loop failures |

The console exporter is enabled by default. Swap it for OTLP or Prometheus in the `.WithMetrics()` / `.WithTracing()` builders in `Program.cs`.

## Project Structure

```
Chat/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Chat.Contracts/          # Shared interfaces and models
â”‚   â”‚   â”œâ”€â”€ IChatHub.cs         # Hub interface
â”‚   â”‚   â”œâ”€â”€ IChatHubReceiver.cs # Client receiver interface
â”‚   â”‚   â”œâ”€â”€ MessageData.cs      # Message model
â”‚   â”‚   â””â”€â”€ Constants.cs        # Shared constants
â”‚   â”œâ”€â”€ Chat.Server/            # Server application
â”‚   â”‚   â”œâ”€â”€ Hubs/
â”‚   â”‚   â”‚   â””â”€â”€ ChatHub.cs      # Hub implementation
â”‚   â”‚   â”œâ”€â”€ Services/
â”‚   â”‚   â”‚   â”œâ”€â”€ ServerNotificationService.cs  # Periodic notifications
â”‚   â”‚   â”‚   â””â”€â”€ ChatHistoryService.cs         # Redis-backed message history
â”‚   â”‚   â”œâ”€â”€ Configuration/
â”‚   â”‚   â”‚   â””â”€â”€ ChatOptions.cs  # App configuration
â”‚   â”‚   â”œâ”€â”€ NoOpReceiver.cs     # Dummy receiver for server-side hub client
â”‚   â”‚   â”œâ”€â”€ Program.cs          # App entry point
â”‚   â”‚   â”œâ”€â”€ appsettings.json
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ Chat.Client/            # Console client
â”‚       â”œâ”€â”€ ChatClient.cs       # Connection lifecycle and auto-reconnect
â”‚       â”œâ”€â”€ ConsoleUI.cs        # Thread-safe coloured console output
â”‚       â”œâ”€â”€ ChatReceiver.cs     # Message receiver implementation
â”‚       â”œâ”€â”€ Configuration/
â”‚       â”‚   â””â”€â”€ ClientOptions.cs  # Client configuration
â”‚       â”œâ”€â”€ Program.cs
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ next-steps.md          # Roadmap and code review findings
â”‚   â””â”€â”€ plans/                 # Implementation plans
â”œâ”€â”€ compose.yaml               # Docker Compose orchestration
â””â”€â”€ Chat.slnx                  # Solution file
```

## How Multi-Server Works

MagicOnion 7.x uses the **Multicaster** library for Redis-based group distribution:

```csharp
// Program.cs - Enable Redis backplane
builder.Services.AddMagicOnion()
    .UseRedisGroup(
        config => config.ConnectionString = redisConnectionString,
        registerAsDefault: true);  // Critical: must be true for cross-server
```

When `registerAsDefault: true`:
1. All `group.All.OnReceiveMessage()` calls are published to Redis
2. All server instances subscribe to the same Redis channel
3. Each server broadcasts to its local clients

## Testing Multi-Instance Setup

1. Start with Docker Compose: `docker compose up --build`
2. Connect client to instance 1: `docker compose run --rm chat.client` (enter `http://chat.server:8080`)
3. Connect another client to instance 2: `docker compose run --rm chat.client` (enter `http://chat.server.2:8080`)
4. Send messages from either client - both receive messages via Redis backplane

## Production Considerations

âœ… **Implemented:**
- Structured logging with Serilog
- Health checks (liveness and readiness, Redis reuses singleton connection)
- Message serialization with MessagePack
- Multi-instance support via MagicOnion Redis backplane
- Docker health checks
- OpenTelemetry metrics and tracing with console exporter (application metrics, ASP.NET Core, runtime, gRPC client)
- NGINX rate limiting (100 req/s per IP, burst 50)
- Kestrel connection limits (1 000 concurrent connections, 100 HTTP/2 streams per connection)
- Graceful shutdown in `ServerNotificationService` with reconnection loop
- `DateTimeOffset` timestamps for round-trip-safe MessagePack serialization
- Redis-backed chat history (`LPUSH`+`LTRIM`, configurable cap, replayed on connect)
- Server-side message-length validation
- Client auto-reconnect with configurable retry (`MaxReconnectAttempts`)

See [docs/next-steps.md](docs/next-steps.md) for the full roadmap.

ðŸ”œ **Consider for production:**
- Authentication & authorization
- Durable message persistence (database â€” Redis history is ephemeral if Redis data is lost)
- User presence tracking
- TLS/SSL certificates
- Swap console exporter for OTLP or Prometheus

## License

MIT
